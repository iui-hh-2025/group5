<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<title>Factbook: User Impact</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="../styles/main.css">
</head>

<body>
	<div class="grid-container">
	<nav>
		<ul>
			<li><a href="../index.html">Home</a></li>
			<li><a href="recognizingai.html">Recognizing AI</a></li>
			<li><a href="userimpact.html">User Impact</a></li>
			<li><a href="policies.html">AI Policies</a></li>
			<li><a href="factchecking.html">AI for Fact-Checking</a></li>
		</ul>
	</nav>
	
	<header>
		<h1>Factbook: AI and Misinformation on Facebook</h1>
		<h2>User Impact and Psychology</h2>
	</header>

	<main>
		<section>
			<h3>Introduction</h3>
			<p>Social media platforms, like Facebook, recommend content to users based on a computer-generated algorithm. The algorithm is mainly formed from three things: the kinds of posts a user engaged with, sponsored posts, and posts that you may be interested in based on what the platform knows about you.</p>
			<p>Over the last couple of years, the use of generative AI on social media sites has had a huge impact on user feeds. For many, these feeds have been flooded with a new wave of AI generative content, much of which presents itself as “real” (non-AI). How much of this content a user is fed is based on their unique, personalized algorithm. Basically, if Facebook thinks a user is more likely to fall for and/or interact with AI content, it will feed them more of it.</p>
			<p>Based on our research and personal experiences, we believed that there may be a correlation between a user's age and the amount of generative AI included in their algorithm. To find out for sure, we decided to do a case study using fake Facebook accounts. The following is an account of that study.</p>
		</section>

		<section>
			<h3>The Study</h3>
			<p>For this case study, I created two Facebook accounts: one for Rita Coleman (age 63) and one for Lauren Meijer (age 21). I used identical demographic information for both accounts (Caucasian and from Indianapolis) and created profile pictures using Canva’s AI generation software “Magic Media.”</p>
			<div class="image-group">
				<img src="../img/Rita.png" alt="AI-generated image of Rita">
				<img src="../img/Lauren.jpg" alt="AI-generated image of Lauren">
			</div>
			<p>After setting up the profiles, I sent friend requests to the first ten people Facebook suggested. Then, I hopped on the feed to see what kinds of posts Facebook’s algorithm would throw at me with the limited information it had. Specifically, I was looking to see how much, and what kinds of AI-generated content each feed would contain.</p>

			<p>Right from the start, Rita’s feed, to put it frankly, was an AI-generated nightmare. In the span of about an hour, I encountered 74 posts containing AI-generated components. Some of the more obvious posts included videos of people saving and/or bathing exotic animals, children falling into gorilla enclosures/being cared for by gorillas, and photos of young children next to marvelous things they supposedly “created.”</p>
			<div class="image-group">
				<img src="../img/man-with-eagle.png" alt="AI-generated man with eagle">
			</div>
			<p>Along with being blurry or choppy in a way that indicated AI generation, the posts were also suspicious due to their improbable content. Comments on these posts varied—some called out the fakeness, but many simply said “Wow!” or “Beautiful!”</p>
			<div class="image-group">
				<img src="../img/owls.png" alt="AI-generated image of owl and babies">
				<img src="../img/owls-comments.png" alt="Facebook comment section under owl post">
			</div>
			<p>Another type of post was subtler: it looked normal at first glance, but closer inspection revealed odd details. These were often aesthetic posts—landscapes, dream homes, recipes, and wildlife.</p>
			<div class="image-group">
				<img src="../img/rainbow-tornado.png" alt="AI-generated tornado with rainbow">
				<img src="../img/Trump.png" alt="AI-generated man eating dumplings">
			</div>
			<p>The final category of AI posts were hard to detect without fact-checking. Many appeared as news articles from sources like NewsBreak. I discovered that, while the stories were real, <a href="https://www.nbcnews.com/tech/tech-news/top-news-app-us-chinese-origins-writes-fiction-help-ai-rcna155567" target="_blank">NewsBreak has been cited multiple times for using AI to create content</a> and presenting it as legitimate journalism.</p>

			<p>The more I engaged with AI content, the more the feed was filled with it. By the end of the hour, Rita’s feed was 80-90% AI-generated content.</p>

			<p>Lauren’s feed was different. While she still received some AI-generated content, it was less frequent and less aggressive. Most of the posts were typical—memes, recipes, sports, celebrities. Aesthetic AI images were the main overlap.</p>
		</section>

		<section>
			<h3>Conclusion</h3>
			<p>Facebook made major assumptions based on age. Rita’s feed was filled with AI-heavy, emotional, and sensational posts, while Lauren’s was more typical and culturally neutral. These assumptions, though algorithmically driven, reinforce harmful stereotypes and misinformation vulnerabilities.</p>

			<p>Older users, unfamiliar with AI or how to spot it, are more likely to engage with and share it. As technology progresses, media literacy becomes even more critical—especially when trusted platforms quietly promote generated content as real.</p>
		</section>

		<section>
			<a href="policies.html">Next Page: Policies on AI</a>
		</section>
	</main>

	<footer>
		<p>This website was created as part of a collaboration between Haaga-Helia University of Applied Sciences and Indiana University Indianapolis. Learn more about the project and how it was made on <a href="https://github.com/iui-hh-2025/group5" target="_blank">our GitHub repository</a>.</p>
	</footer>
	</div>
</body>
</html>
