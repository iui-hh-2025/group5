<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<title>Factbook: User Impact</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="../styles/main.css">
</head>

<body>
	<div class="grid-container">
	<nav>
		<ul>
			<li><a href="../index.html">Home</a></li>
			<li><a href="recognizingai.html">Recognizing AI</a></li>
			<li><a href="userimpact.html">User Impact</a></li>
			<li><a href="policies.html">AI Policies</a></li>
			<li><a href="factchecking.html">AI for Fact-Checking</a></li>
		</ul>
	</nav>
	
	<header>
		<h1>Factbook: AI and Misinformation on Facebook</h1>
		<h2>User Impact and Psychology</h2>
	</header>

	<main>
		<section>
			<h3>Introduction</h3>
			<p>Social media platforms, like Facebook, recommend content to users based on a computer-generated algorithm. The algorithm is mainly formed from three things; the kinds of posts a user engaged with, sponsored posts, and posts that you may be interested in based on what the platform knows about you.
				<br>
Over the last couple years, the use of generative AI on social media sites has had a huge impact on user feeds. For many, these feeds have been flooded with a new wave of AI generative content, much of which presents itself as “real” (non-AI). How much of this content a user is fed is based on their unique, personalized algorithm. Basically, if Facebook thinks a user is more likely to fall for and/or interact with AI content, it will feed them more of it.
				<br>
Based on our research and personal experiences, we believed that there may be a correlation between a user's age and the amount of generative AI included in their algorithm. To find out for sure, we decided to do a case study, using fake Facebook accounts. The following is an account of that study.  
</p>
		</section>
		<section>
			<h3>The Study</h3>
			<p>For this case study, I created two Facebook accounts; one for Rita Coleman (age 63) and one for Lauren Meijer (age 21). I used identical demographic information for both accounts (caucasian and from Indianapolis) and created profile pictures using Canva’s AI generation software “Magic Media.” This program generates images based on a given prompt. For Rita I used the prompt “60 year old caucasian woman and her family.” I chose the most believable option. Up close it is clearly AI generated, but as a little icon it was passable. 
For Lauren I used the prompt “young caucasian woman celebrating graduation” as that Is something a 21 year old would likely have as their profile picture.
				<br>
				<!--Insert images: "Rita" and "Lauren"-->
After setting up the profiles, I sent friend requests to the first ten people Facebook suggested. Then, I hopped on the feed to see what kinds of posts Facebook’s algorithm would throw at me with the limited information it had. Specifically, I was looking to see how much, and what kinds of AI generated content each feed would contain. Would the user’s age affect how much AI content was recommended? And If so, who would be recommended more, Rita (an older user) or Lauren (a younger user)? 
				<br>
Right from the start, Rita’s feed, to put it frankly, was an AI generated nightmare. In the span of about an hour, I encountered 74 posts containing AI generated components. Some of the more obvious posts included things like: videos of people saving and/or bathing exotic animals, videos of children falling into gorilla enclosures/ being cared for by the gorilla, and photos of young children next to marvelous things they “created.”
				<br>
				<!--Insert image: "man with eagle"-->
Along with being smooth, blurry, and choppy in a way which indicated AI generation, the posts were also suspicious because of the improbable nature of the content. I looked at the comments for some of these posts to see what other people were saying. A few of the comments criticized the post’s phoniness and use of AI, but most people seemed to fall for it, simply commenting: “Wow!” “Beautiful!” or “God is great!”
				<!--Insert images: "owls" and "owls comments"-->
				<br>
Most of the AI posts fell into another category: AI upon close inspection. These posts seemed normal at first, but when you look closely, you start to notice that things are just a little bit off. insert photos. These appeared mostly as aesthetic posts (exotic landscapes/ flora and fauna, dream houses, and must-try recipes). 
				<!--Insert images: "rainbow tornado" and "Trump"-->
				<br>
The last group of AI posts was much harder to spot and usually involved fact checking from a source outside of Facebook (ex: an internet search). Most of these posts on Rita’s feed appeared in the form of articles about African American Men being arrested for drug offenses posted by an account called “NewsBreak.” After doing some research, I found that while the crimes being reported in the Newsbreak articles I encountered were real, <a href="https://www.nbcnews.com/tech/tech-news/top-news-app-us-chinese-origins-writes-fiction-help-ai-rcna155567">the outlet has been cited multiple times for posting AI generated content and labeling it as real news.</a> Top news app in U.S. has Chinese origins and 'writes fiction' with the help of AI. (create hyperlink)
				<br>
The more I interacted with AI content, the more of it littered Rita’s feed. By the end of my scrolling session, the content was somewhere between 80% and 90% AI garbage. 
				<br>
My experience on Lauren’s feed was vastly different. While there was still AI generated content, it was far less frequent and far more subtle. I recognized a few of the same phony animal rescue videos from Rita’s feed, but mostly the AI was contained to aesthetic images. 
As with Rita’s feed, the more I interacted with AI generated posts, the more of them appeared. By the end of the hour session, I had only seen 26 posts with AI components. Rather than the senseless garbage that had made up Rita’s feed. Lauren’s was filled with pretty normal posts of recipes, sports, cars, celebrity references, and memes. The only main overlap seemed to be the AI generated aesthetic posts of flowers and landscapes.</p>
		</section>
		<section>
			<h3>Conclusion</h3>
			<p> Facebook seemed to assume quite a few things about both people based solely on age and location. Rita was assumed to be Christian, a little bit racist, and an easy target for AI misinformation. Lauren, on the other hand, had nothing assumed about her religion or political views, but was assumed to be “too smart” to fall for AI. These kinds of assumptions can be very harmful (not to mention incorrect). 
				<br>
			AI content is targeted towards older people because they are seen as more likely to fall for and share it. Technology advances at a very fast rate, and it can be hard to keep up with everything new, like generative AI. For those who don’t work much with IT, and are not used to computer programs being able to do certain things (like generate fake, yet realistic images), AI can be hard to spot. They may also not even know that they should be looking out for AI in the first place. It’s especially difficult when trusted media outlets are the ones spreading this content without stating that it’s fake.</p>
		</section>
		<section>
			<a href="policies.html">Next Page: Policies on AI</a>
		</section>
	</main>

	<footer>
		<p>This website was created as part of a collaboration between Haaga-Helia University of Applied Sciences and Indiana University Indianapolis. Learn more about the project and how it was made on <a href="https://github.com/iui-hh-2025/group5">our GitHub repository</a>.</p>
	</footer>
	</div>
</body>

</html>
